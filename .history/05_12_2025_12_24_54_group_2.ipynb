{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e93e9cf8-64fe-4215-b7f5-47f72e20904a",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d3e06-d8aa-46d5-b660-ba7c2a28684c",
   "metadata": {},
   "source": [
    "A Minecraft server set up by a research group in Computer Science at UBC, led by Frank Wood, aims to refine its recruitment efforts such that they can handle the number of players they attract.\n",
    "\n",
    "The following project discusses the broad question of what player characteristics/behaviours are most predictive of a subscription to the game-related newsletter, and we sought to answer:\n",
    ">What are the optimal variables and model that optimizes the prediction of the probability of a subscription occurring in the players.csv dataset?\n",
    "\n",
    "We chose this dataset as it contains the relevant variables such as Age, Hours played, and Experience level.\n",
    "\n",
    "**About the Data**\n",
    "\n",
    "Players.csv includes a list of all unique players, including their recorded data:\n",
    "\n",
    "| Type | Total observations |\n",
    "| :------------ | :-----------: \n",
    "| Observations (rows)  | 196 |\n",
    "| Variables (columns)   | 7 |\n",
    "\n",
    "\n",
    "| Variable | Type | Description |\n",
    "| :------------ | :-----------: | ------------: |\n",
    "| experience | Chr | User experience level |\n",
    "| subscribe | Igl  | Subscription |\n",
    "| hashedEmail | chr | Hashed email identifier |\n",
    "| played-hours | dbl | Hours played |\n",
    "| name | chr | Username |\n",
    "| gender | chr | Gender |\n",
    "| Age | dbl | Age in years |\n",
    "\n",
    "**About the Data Collection**\n",
    "\n",
    "- Players' actions are recorded as they navigate through the world\n",
    "- Collected more than 10,000 hours of over ten thousand multiplayer Minecraft gameplay\n",
    "- The project records spoken interactions between players from the player's microphone.\n",
    "- The \"experience\" column in the players.csv file was collected on a self-declared basis as users signed up\n",
    "\n",
    "**Potential Issues with the Data**\n",
    "\n",
    "- Age range implications - parental consent for players under 13, \"The parent can revoke consent any time\"\n",
    "- Geographic ties - individuals who respond are likely UBC students or those who saw promotions\n",
    "- Access to the study - Individuals who may never get the access link to Plaicraft/never discover the study\n",
    "- Ability to delete recorded data -\"provide us with session ID (found in the email or SMS with your access link) of the game session you would like us to delete. Alternatively, email support@plaicraft.ai for assistance.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982bfe96-7ebd-4c27-a2db-846c7592e774",
   "metadata": {},
   "source": [
    "# 2. Wrangling\n",
    "\n",
    "To prepare the data for analysis, we first loaded the `players.csv` and `sessions.csv` files and inspected their structure with `glimpse()`. The players dataset contains demographics, subscription status, and total played hours for each user. Following our project plan, we removed players with `played_hours == 0`, since these users do not provide any behavioural information relevant to predicting subscription. We also excluded rows with missing values in `subscribe` or `played_hours`, and converted the categorical variables (`experience`, `gender`, `subscribe`) into factors. \n",
    "\n",
    "The sessions dataset required additional wrangling because its timestamps were stored as character strings. Using `separate()`, we extracted date, hour, and minute components from each start and end time, and computed a new variable `duration_min` to represent each session length. We removed sessions with zero or negative duration, then summarized each user's gameplay by calculating their number of sessions (`n_sessions`) and average session length (`mean_session_min`). These summaries were useful for exploratory analysis but were not included as predictors in the final models, which focused on the variables that performed best during tuning (Age, played_hours, and experience). Session-level summaries (n_sessions, mean_session_min) were explored but excluded from modeling because they did not improve accuracy during tuning.\n",
    "\n",
    "After cleaning, we generated summary statistics to understand overall gameplay behavior. The distribution of played hours is highly right-skewed, with most players having less than one hour of total playtime and a small number recording extremely high totals. Boxplots comparing played hours by subscription show that subscribed players tend to have slightly higher engagement on average.\n",
    "\n",
    "We also examined the balance of the outcome variable(`subscribe`). The majority of players in our dataset are subscribers, which means the data is moderately imbalanced. Understanding this imbalance is important because classification accuracy can be misleading when one class dominates where a model may achieve high accuracy simply by predicting the majority class. This class balance summary provides context for interpreting the performance of both the KNN and logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d959ad-3490-40ff-b4df-9eef999a8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages({library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(themis)})\n",
    "set.seed(1234)\n",
    "\n",
    "players <- read_csv(\"data/players.csv\")\n",
    "sessions <- read_csv(\"data/sessions.csv\")\n",
    "glimpse(players)\n",
    "glimpse(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b6f39-ae3b-4b4d-9ddf-899f97df4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangling - Clean players dataset\n",
    "players_clean <- players |>\n",
    "    filter(!is.na(subscribe), !is.na(played_hours), played_hours > 0) |>\n",
    "    mutate(subscribe = factor(subscribe), gender = factor(gender), experience = factor(experience))\n",
    "glimpse(players_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413478bb-d5ae-4d61-8810-c1aa130ffb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangling - Clean sessions dataset\n",
    "sessions_clean <- sessions |>\n",
    "    separate(start_time, into = c(\"start_date\", \"start_clock\"), sep = \" \") |>\n",
    "    separate(end_time, into = c(\"end_date\", \"end_clock\"), sep = \" \") |>\n",
    "    separate(start_clock, into = c(\"start_hour\", \"start_minute\"), sep = \":\", convert = TRUE) |>\n",
    "    separate(end_clock, into = c(\"end_hour\", \"end_minute\"), sep = \":\", convert = TRUE) |>\n",
    "    mutate(duration_min = (end_hour - start_hour) * 60 + (end_minute - start_minute)) |>\n",
    "    filter(duration_min > 0)\n",
    "glimpse(sessions_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abfb7f-feaa-4dae-9eca-31736defdb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize sessions per player\n",
    "sessions_summary <- sessions_clean |>\n",
    "    group_by(hashedEmail) |>\n",
    "    summarize(n_sessions = n(), mean_session_min = mean(duration_min))\n",
    "glimpse(sessions_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31132e36-9f5d-447c-aed6-9b6923885520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join players + session summaries\n",
    "players_final <- players_clean |>\n",
    "    left_join(sessions_summary, by = \"hashedEmail\")\n",
    "glimpse(players_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badaff88-384f-4ca7-83f2-99952437d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats\n",
    "\n",
    "# Overall\n",
    "players_final |>\n",
    "    summarize(\n",
    "        mean_hours = mean(played_hours),\n",
    "        median_hours = median(played_hours),\n",
    "        sd_hours = sd(played_hours),\n",
    "        subscription_rate = mean(subscribe == \"TRUE\"))\n",
    "\n",
    "# Subscription rate by experience\n",
    "players_final |>\n",
    "    group_by(experience) |>\n",
    "    summarize(subscription_rate = mean(subscribe == \"TRUE\"))\n",
    "\n",
    "# Subscription rate by gender\n",
    "players_final |>\n",
    "    group_by(gender) |>\n",
    "    summarize(subscription_rate = mean(subscribe == \"TRUE\"))\n",
    "\n",
    "# Class balance\n",
    "players_final |>\n",
    "  count(subscribe) |>\n",
    "  mutate(prop = n / sum(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd2fac-384c-4467-b514-5942e9e24ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot_height = 20, repr.plot_width = 20)\n",
    "ggplot(players_final, aes(x = played_hours)) +\n",
    "    geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"black\") +\n",
    "    labs(x = \"Played Hours\", y = \"Count\", title = \"Distribution of Player Hours\") +\n",
    "    theme(text = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e520d-8961-4f62-ada2-4ac8c9a64b7b",
   "metadata": {},
   "source": [
    "**Figure 1.** Distribution of played hours (full scale). This histogram shows that the distribution is extremely right-skewed, with a few players recording very high totals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67cf0a-3413-4ad0-ad1b-3ae7062a2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot_height = 20, repr.plot_width = 20)\n",
    "ggplot(players_final, aes(x = played_hours)) +\n",
    "    geom_histogram(binwidth = 1, fill = \"skyblue\", color = \"black\") +\n",
    "    coord_cartesian(xlim = c(0, 10)) +\n",
    "    labs(x = \"Played Hours\", y = \"Count\", title = \"Distribution of Player Hours\") +\n",
    "    theme(text = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9145c9-bf0f-418c-bc63-cfeee4f1988c",
   "metadata": {},
   "source": [
    "**Figure 2.** Distribution of played hours (0-10 hours). Zooming in on the lower range shows that most players have played under two hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb2936-ef17-4339-a470-4add41cf7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(players_final, aes(x = subscribe, y = played_hours)) +\n",
    "    geom_boxplot(fill = \"skyblue\") +\n",
    "    labs(x = \"Subscription Status\", y = \"Played Hours\", title = \"Played Hours by Subscription Status (Full Scale)\") +\n",
    "    theme(text = element_text(size = 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69bf753-297a-4ec8-b3eb-eb098814ec7d",
   "metadata": {},
   "source": [
    "**Figure 3.** Boxplot of played hours by subscription status (full scale). Subscribed players tend to show slightly higher engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be906d-8a57-4333-9ab2-5e4372bd3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(players_final, aes(x = subscribe, y = played_hours)) +\n",
    "    geom_boxplot(fill = \"skyblue\") +\n",
    "    coord_cartesian(ylim = c(0, 10)) +\n",
    "    labs(x = \"Subscription Status\", y = \"Played Hours\", title = \"Played Hours by Subscription Status (Zoomed)\") +\n",
    "    theme(text = element_text(size = 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2435b6-6197-4c9e-aa32-c37975b95284",
   "metadata": {},
   "source": [
    "**Figure 4.** Boxplot of played hours by subscription status, zoomed to 0-10 hours for clarity. This highlights that most players play very little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3541cc1-82ae-426e-bd73-9502cc70c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_final |>\n",
    "    count(subscribe) |>\n",
    "    mutate(prop = n / sum(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e1b09-3975-4469-bfc8-dd013232562a",
   "metadata": {},
   "source": [
    "These cleaned data support our exploratory analysis. The final models use the predictors that performed best during tuning: Age, played_hours, and experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0403869d-f216-4a4a-9ce6-3f11342b92ce",
   "metadata": {},
   "source": [
    "# 3. Dealing With Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae059186-86eb-4460-97e8-aae72e1b8dc3",
   "metadata": {},
   "source": [
    "**Legend of Visualizations:**\n",
    "| Figure # | Section | Description |\n",
    "| :------------ | :-----------: | :------------ |\n",
    "| 1| 2 | Distribution of played hours (full scale) |\n",
    "| 2 | 2 | Distribution of played hours (0-10 hours) |\n",
    "| 3| 2 | Boxplot of played hours by subscription status (full scale) |\n",
    "| 4 | 2 | Boxplot of played hours by subscription status (0-10) hours |\n",
    "| 5| 4.1 |  Line plot of Mean Accuracy  |\n",
    "| 6 | 4.1 | Classification outcome scatterplot|\n",
    "| 6.1 | 4.1 | Density plot of probability - KNN|\n",
    "| 7 | 4.2 | Density plot of probability - Regression |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2555df3-9b8f-4477-b34f-c30623034565",
   "metadata": {},
   "source": [
    "# 4.1 Data Analysis - Part 1: Classification Model\n",
    "Many different approaches to a classification model for newspaper subscriptions are possible. Therefore, there are specific parameters that have been set:\n",
    "* 70/30 training/testing split\n",
    "* 5-fold cross-validation\n",
    "* target: subscribe\n",
    "* all predictors: experience, age, played_hours\n",
    "\n",
    "### Methodology\n",
    "For the first part of making the classification model, the goal was to select the model with predictors that give the highest accuracy. The three predictors from which combinations were made were: `experience`, `age`, and `played_hours`.\n",
    "\n",
    "To be able to use experience as a predictor, the factors amateur to veteran were converted to a scale of 1 to 5. \n",
    "\n",
    "The players dataset was then split into training and testing with a 70:30 train-test split, stratified by the subscriber status. \n",
    "\n",
    "After this, recipes were formed for each combination of predictors, in which the data was also standardized. These recipes were used in tuning the number of nearest neighbors, k. Values of k from 2 to 10 and cross-validation with 5 folds, again stratified by subscriber status, were used in the tuning. The classification model was set to work through k-NN. \n",
    "\n",
    "For each of the recipes, the highest accuracy produced with 2$\\leq$k$\\leq$10 were tabulated and arranged in order from largest to smallest. The recipe producing the highest accuracy, which was the recipe including `played_hours` and `age` as predictors, was then plotted as mean accuracy vs each k, as shown in Figure 5. The highest k with the lowest fluctation around it was then identified visually to be k=5. \n",
    "\n",
    "Using an adjusted model with the found optimal recipe including `played_hours` and `age` and nearest neighbors k=5, the training model was fit. \n",
    "\n",
    "The model was then used to classify the testing data. The accuracy, kap value, and confusion matrix for the model were produced based on this.\n",
    "\n",
    "The model for classification was then used to also predict the probabilities of subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba81f7-151a-42da-a047-f43e21cb8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the experience numerical\n",
    "players_for_model <- players_final |>\n",
    "    mutate(experience = as.numeric(factor(experience, levels = c(\"Amateur\", \"Beginner\", \"Regular\", \"Pro\", \"Veteran\")))) |>\n",
    "    na.omit()\n",
    "head(players_for_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8335b-0b4a-486f-87cd-3631b4ee86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "#Splitting into training and testing\n",
    "player_split <- initial_split(players_for_model, prop = .7, strata = subscribe)\n",
    "player_training <- training(player_split)\n",
    "player_testing <- testing(player_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23513a2c-2bb5-4fab-a17e-6325d9035501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the recipes:\n",
    "#played_hours = H, Age = A, experience = E\n",
    "\n",
    "newspaper_AE_recipe <- recipe(subscribe ~ experience + Age, data = player_training) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    step_scale(all_predictors()) \n",
    "                        \n",
    "\n",
    "newspaper_AH_recipe <- recipe(subscribe ~ played_hours + Age, data = player_training) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    step_scale(all_predictors())\n",
    "\n",
    "newspaper_HE_recipe <- recipe(subscribe ~ experience + played_hours, data = player_training) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    step_scale(all_predictors())\n",
    "\n",
    "newspaper_A_recipe <- recipe(subscribe ~ Age, data = player_training) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    step_scale(all_predictors()) \n",
    "\n",
    "newspaper_H_recipe <- recipe(subscribe ~ played_hours, data = player_training) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    step_scale(all_predictors())\n",
    "\n",
    "newspaper_E_recipe <- recipe(subscribe ~ experience, data = player_training) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    step_scale(all_predictors()) \n",
    "\n",
    "#Recipe for all 3 parameters\n",
    "newspaper_3C3_recipe <- recipe(subscribe ~ experience + played_hours + Age, data = player_training) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    step_scale(all_predictors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee4e8f-e06a-47be-847c-060b66b52f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "#TUNING K\n",
    "train_fold <- vfold_cv(player_training, v=5, strata = subscribe)\n",
    "k_vals <- tibble(neighbors = seq(from = 2, to = 10, by = 1))\n",
    "\n",
    "#Make model for k tuning\n",
    "knn_tune <- nearest_neighbor(weight_func = 'rectangular', neighbors = tune()) |>\n",
    "    set_engine('kknn') |>\n",
    "    set_mode('classification')\n",
    "\n",
    "#initialize tibble\n",
    "highest_acc_per_recipe = tibble(recipe_name = character(), accuracy = numeric())\n",
    "\n",
    "tune_k <- function(recipe, recipe_name) {\n",
    "    #Workflow to get metrics for k tuning\n",
    "    newspaper_workflow <- workflow() |>\n",
    "        add_recipe(recipe) |>\n",
    "        add_model(knn_tune) |>\n",
    "        tune_grid(resamples = train_fold, grid = k_vals) |>\n",
    "        collect_metrics()\n",
    "\n",
    "    #Find the highest accuracy per recipe\n",
    "    highest_accuracy <- newspaper_workflow |>\n",
    "        filter(.metric == 'accuracy') |>\n",
    "        arrange(desc(mean)) |>\n",
    "        slice(1) |>\n",
    "        pull(mean)\n",
    "\n",
    "    #Add to tibble\n",
    "    highest_acc_per_recipe <<- highest_acc_per_recipe |>\n",
    "        add_row(recipe_name = recipe_name, accuracy = highest_accuracy)\n",
    "    \n",
    "    }\n",
    "\n",
    "tune_k(newspaper_3C3_recipe, '3C3 Recipe')\n",
    "tune_k(newspaper_AE_recipe, 'AE Recipe')\n",
    "tune_k(newspaper_AH_recipe, 'AH Recipe')\n",
    "tune_k(newspaper_HE_recipe, 'HE Recipe')\n",
    "tune_k(newspaper_A_recipe, 'A Recipe')\n",
    "tune_k(newspaper_H_recipe, 'H Recipe')\n",
    "tune_k(newspaper_E_recipe, 'E Recipe')\n",
    "\n",
    "ordered_highest_acc_per_recipe <- highest_acc_per_recipe |>\n",
    "    arrange(desc(accuracy))\n",
    "\n",
    "ordered_highest_acc_per_recipe\n",
    "\n",
    "# The highest accuracy is found with Age and Mean Played Hours as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b2bbb-bbc8-49c8-b232-735a5888390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning k for Age+played_hours as predictors\n",
    "set.seed(1234)\n",
    "\n",
    "train_workflow <- workflow() |>\n",
    "    add_recipe(newspaper_AH_recipe) |>\n",
    "    add_model(knn_tune) |>\n",
    "    tune_grid(resamples = train_fold, grid = k_vals) |>\n",
    "    collect_metrics()\n",
    "\n",
    "#Make the plot to see which k gives optimal accuracy\n",
    "cross_val_plot <- train_workflow |>\n",
    "    filter(.metric == 'accuracy') |>\n",
    "    ggplot(aes(x = neighbors, y = mean)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    ggtitle(\"Mean of Accuracy vs K\")+\n",
    "    labs(x = 'Number of Neighbors (k)', y = 'Mean of Accuracy')\n",
    "\n",
    "cross_val_plot\n",
    "\n",
    "#plot shows that k=5 gives the highest accuracy (with least fluctutation around it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904e2b4-d2ad-4a6e-8ec0-dbc874672369",
   "metadata": {},
   "source": [
    "**Figure 5.** Line plot of mean accuracy shows that k=5 gives the highest accuracy (with least fluctuation around it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6471c-c951-4ea4-8146-7933ebb88400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, using k=5 and newspaper_AH_recipe:\n",
    "set.seed(1234)\n",
    "\n",
    "newspaper_AH_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 5) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\")\n",
    "   \n",
    "\n",
    "newspaper_AH_fit <- workflow() |>\n",
    "    add_recipe(newspaper_AH_recipe) |>\n",
    "    add_model(newspaper_AH_spec) |>\n",
    "    fit(data = player_training)\n",
    "newspaper_AH_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d2d70-7702-4f50-b353-c30e562474c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "#TESTING\n",
    "\n",
    "newspaper_predictions <- predict(newspaper_AH_fit, player_testing) |>\n",
    "    bind_cols(player_testing)\n",
    "# newspaper_predictions\n",
    "\n",
    "newspaper_metrics <- metrics(newspaper_predictions, truth = subscribe, estimate = .pred_class)\n",
    "newspaper_metrics\n",
    "\n",
    "newspaper_conf_mat <- conf_mat(newspaper_predictions, truth = subscribe, estimate = .pred_class)\n",
    "newspaper_conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28098fdf-f9ce-4273-9e5e-453d249a1d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper_predictions <- newspaper_predictions |>\n",
    "  mutate(conf_type = case_when(\n",
    "      subscribe == TRUE  & .pred_class == TRUE  ~ \"True Positive\",\n",
    "      subscribe == FALSE & .pred_class == FALSE ~ \"True Negative\",\n",
    "      subscribe == FALSE & .pred_class == TRUE  ~ \"False Positive\",\n",
    "      subscribe == TRUE  & .pred_class == FALSE ~ \"False Negative\"))\n",
    "\n",
    "knn_sp<-ggplot(newspaper_predictions, aes(x = Age, y = played_hours)) +\n",
    "  geom_point(aes(color = conf_type), size = 3 , alpha = 0.5) +\n",
    "  scale_color_manual(values = c(\n",
    "    \"True Positive\" = \"blue\",\n",
    "    \"True Negative\" = \"green\",\n",
    "    \"False Positive\" = \"red\",\n",
    "    \"False Negative\" = \"orange\")) +\n",
    "  labs(title = \"Classification Outcome Visualization (TP, TN, FP, FN)\",\n",
    "    color = \"Confusion Type\")\n",
    "knn_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29469823-3a67-49d4-a605-6669accaf51e",
   "metadata": {},
   "source": [
    "**Figure 6.** Scatterplot of knn classification outcomes helps us understand the confusion matrix. We can clearly see areas where FP overlaps TP (where the classification is not successful) and potential outliers or noisy points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098002b-2362-4678-8a8f-cd99dabf5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for KNN\n",
    "newspaper_predictions2 <- predict(newspaper_AH_fit, player_testing, type = \"prob\") |>\n",
    "    bind_cols(player_testing)\n",
    "\n",
    "ppd_dist_KNN<-ggplot(newspaper_predictions2, aes(x = .pred_TRUE, fill = subscribe)) +\n",
    "    geom_density(alpha = 0.5) +\n",
    "    ggtitle(\"Distribution of Predicted probability of Subscripiton - KNN\")+\n",
    "    labs(x = \"Predicted Probability of Subscription\", y = \"Density\")\n",
    "ppd_dist_KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f967fa-8f87-4c4e-b5b2-75066763c5ee",
   "metadata": {},
   "source": [
    "**Figure 6.1** Plot visualizes the density vs probability of subscriptions, true or false, from the KNN model. Areas with overlap indicate that at some probability,  the model assigns similar probabilities to both classes, making it difficult to distinguish them. This plot shows significant overlap, which makes sense for our predicted accuracy of 65.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b323c341-c1ed-42bf-8ad9-087a094cfd53",
   "metadata": {},
   "source": [
    "# 4.2 Data Analysis - Part 2: Logistic Regression Model\n",
    "In part 4.2, a logistic regression model is used to predict the subscription status of each player in the testing data.\n",
    "\n",
    "We chose Logistic Regression over other classification methods because our outcome variable, subscribe, is a logical (binary) variable with only two options, which are True or False. Since we cannot predict a continuous number for a logical variable, we cannot use linear and KNN regression methods that calculate the distance from a line. Instead, we use Logistic Regression to calculate the probability (likelihood) that a specific observation belongs to the 'True' category.\n",
    "\n",
    "Unlike the classification we have been doing in the course so far, we can not output TRUE/FALSE directly, as there is no guarantee that our classification is rarely 100% certain. Instead, there is a certainty of each observation to be classified right. In one case, we are 51% confident that this person belongs to the TRUE category. In another case, we are 90% confident that this person belongs to the TRUE category. In the classification that we have been doing so far, we don’t take into account how confident our classification is, which can not be a good statistical measure.\n",
    "\n",
    "### Methodology\n",
    "Firstly, the model specification for the logistic regression model was set by the logistic_reg() function. Since we are eventually classifying the data using logistic regression, the classification mode was used in specification. \n",
    "\n",
    "Then the workflow was built by using the specification of logistic regression model and recipe with Age and Hours predictors, which was found to yield the prediction with the highest accuracy in KNN classification model from part 4.1. \n",
    "\n",
    "Subsequently, the workflow was passed to fit the training data into the model and train the logistic regression model.  \n",
    "\n",
    "After fitting the model, the predict() function was used to actually predict the testing data using the trained logistic regression model. \n",
    "\n",
    "Then, the column of predictions was attached to the original data frame containing true subscription status. Using this, a confusion matrix that quantifies the number of true positive predictions out of all predictions was built using a conf_mat() function to determine the accuracy of the logistic regression model. Then, the metrics that indicate the accuracy and kappa value of the model was built by a metrics() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afca393-17fd-412d-9218-6ba57221af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the model specification\n",
    "log_spec <- logistic_reg() |> \n",
    "  set_engine(\"glm\") |> \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# 2. Build the workflow\n",
    "probability_workflow <- workflow() |> \n",
    "  add_model(log_spec) |> \n",
    "  add_recipe(newspaper_AH_recipe)\n",
    "\n",
    "# 3. Fit the model to the training data & Evaluate on the test set\n",
    "probability_fit <- probability_workflow |> \n",
    "  fit(data = player_training)\n",
    "\n",
    "# We predict both the class (.pred_class) and the probabilities (.pred_TRUE)\n",
    "news_AH_predictions <- predict(probability_fit, player_testing) |> \n",
    "  bind_cols(predict(probability_fit, player_testing, type = \"prob\")) |> \n",
    "  bind_cols(player_testing)\n",
    "# news_AH_predictions\n",
    "\n",
    "# 4. Performance Metrics for Class Prediction\n",
    "# Confusion Matrix\n",
    "simple_conf_mat <- conf_mat(news_AH_predictions, truth = subscribe, estimate = .pred_class)\n",
    "simple_conf_mat\n",
    "\n",
    "# Accuracy\n",
    "simple_metrics <- metrics(news_AH_predictions, truth = subscribe, estimate = .pred_class)\n",
    "simple_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c0d61-802d-4aee-8af3-b3624f1f07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_dist_R<-ggplot(news_AH_predictions, aes(x = .pred_TRUE, fill = subscribe)) +\n",
    "    geom_density(alpha = 0.5) +\n",
    "    ggtitle(\"Distribution of Predicted probability of Subscription - Regression\")+\n",
    "    labs(x = \"Predicted Probability of Subscription\", y = \"Density\")\n",
    "ppd_dist_R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f030bb56-f892-4302-861c-6c0e93a79e70",
   "metadata": {},
   "source": [
    "**Figure 7.** Plot visualizes the density vs probability of subscriptions for our Regression model, having less overlap, showing an improved accuracy of 73.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3eb3c-c896-4f98-add4-8a44b2b378af",
   "metadata": {},
   "source": [
    "# 5. Discussion\n",
    "**Conclusion**  \n",
    "Our results show that played hours and age are meaningful predictors of subscription behaviour. Logistic regression produced the strongest predictive performance, with an accuracy of 75.8% compared to 72.7% for KNN Classification. This indicates that logistic regression generalizes better on this dataset and provides more stable probability estimates. This answers our research question by identifying both the most important predictors and the most effective model for estimating subscription probability.\n",
    "\n",
    "**Predictor Expectations and Analysis**  \n",
    "At the beginning of the project, the group hypothesized that the experience and/or played hours variables would be better predictors of subscription status than the age variable.  The initial reasoning was that individuals who are experienced or put more effort into the game must be more passionate and therefore more inclined to subscribe. However, after analysis of accuracy in each predictor, it was discovered that age and played hours were most consequential, suggesting that certain ages that resulted in x amount of hours played would be an area for further investigation. \n",
    "\n",
    "**Model Expectations and Analysis**  \n",
    "For the model, it was predicted that logistic regression would be a better model than KNN. The difference in model performance was as expected. Because the dataset is imbalanced, logistic regression learns that predicting the majority class (TRUE) minimizes error, which inflates accuracy while masking poor performance on the minority class. Although this means it fails to identify any non-subscribers, it performs well on the majority group of subscribers. KNN, which relies on local neighbourhoods, incorrectly predicts some TRUE cases as false and is more affected by noise and imbalance, resulting in lower accuracy overall. For this reason, logistic regression is chosen as the better-performing model in this context, though its inability to detect the minority class remains a limitation.\n",
    "\n",
    "Although the classification model has a precision of 75% and a recall of 96%, these metrics only reflect performance on the positive class. When examining the confusion matrix, it is seen that no true negatives are correctly predicted. Every time a player is not subscribed, they are predicted as being subscribed. However, some players who are suscribed are predicted to not subscribe. The logistic regression model gives a precision of 75.8% and a recall of 100%. This is because the model predicts everything as true, thereby correctly identifying all true subscribers but failing to correctly identify any non-subscribers.\n",
    "\n",
    "Although logistic regression performed better, both models showed low Cohen's kappa values, signalling weak agreement. A kappa value of 0 is given by the logistic regression model, meaning that the agreement between the model’s classifications and true values are, in essence, random. The kNN classification model has a kappa below 0, meaning that the model is even worse at classifying than if classification would have been done with random guessing. This reflects the limited predictive power of the current dataset. Subscription behaviour likely depends on additional factors not captured here, such as game progression, social interactions, or exposure to subscription promotions. The dataset's moderate class imbalance and small size also restrict model accuracy.\n",
    "\n",
    "**Impact**  \n",
    "Despite these limitations, our findings support the idea that played hours and age are the strongest behavioural indicators of subscription. This is useful for identifying potential subscribers and understanding the engagement patterns that lead to more subscribers.\n",
    "\n",
    "**Outlook**  \n",
    "Future work could expand the dataset with more behavioural features (e.g. sessions per week, time of day activity patterns, retention metrics) or evaluate other models (e.g. decision trees, random forests, gradient boosting) not covered in DSCI 100. Collecting longitudinal data would enable modelling how subscription likelihood changes over time. Finally, demographic variables could be examined in combination with engagement metrics to explore whether certain age groups or other categories are more likely to subscribe. This would help identify which potential players are important to target for subscriptions. \n",
    "\n",
    "Overall, logistic regression provides a more accurate and interpretable approach for predicting subscription, and the analysis confirms that hours played and age are key parameters for predicting subscription likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd79377-0f47-4282-9f73-5cb3c7e17c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
